Information theory (the math of data storage), Geometry (the shape of data) and Machine Learning (Dimesion Reduction, probablistic modeling)
# Compression is prediction
## 1. Data compression and probablistic modeling
### 1. Entropy is the true dimension of data. The \b Source Coding Theorem \b quantifies the theoretical compression before information loss.

### 2. Compression is prediction, the "sparse graph codes" relates the sparsity requirement for reduction.
Title: Information Theory, Inference, and Learning Algorithms
Author: David J.C. MacKay

### 3. How we reconstruct signals from very few measurements (compressed sensing), transform coding, dealing with when dimension reduction is lossless vs lossy
Title: Information Theory, Inference, and Learning Algorithms
Author: David J.C. MacKay
